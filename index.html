<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiaqi Ye - UoB</title>
  
  <meta name="author" content="Jiaqi Ye">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
	
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <a href="images/Robotic Lab.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Robotic Lab.jpg" class="hoverZoomLink"></a>  
    </td>
  </tbody></table>

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiaqi Ye</name>
              </p>
              <p>
              I am currently a Research Fellow in Engineering at <a href="https://www.birmingham.ac.uk/index.aspx">University of Birmingham (UoB)</a> and in charge of the<a href="https://www.birmingham.ac.uk/research/railway/facilities-expertise/ukrrin-building-facility.aspx"> Autonomous Systems Lab </a> of<a href= "https://www.ukrrin.org.uk/""> UKRRIN</a>, 
              where I focus on the R&D of intelligent sensing systems and machine learning solutions, particularly vision system and deep learning for computer vision, applied for machinery fault diagnosis, asset management, and generic automation tasks.
              </p>
              <p>
                I did my PhD in Electronic, Electrical and Systems Engineering (EESE) at UoB, where I was supervised by <a href="https://www.birmingham.ac.uk/staff/profiles/eese/roberts-clive.aspx">Clive Roberts</a> and <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>  and funded by the <a href="https://www.birmingham.ac.uk/research/railway/about-us/about-us">BCRRE</a>. 
                During my PhD,I developed two innovative laser scanners with dedicated deep learning algorithms for rapid 3D measuremnt and assessment of substantial objects, such
                as railway tracksÔºõWorked as a core member in multi-disciplinary teams for two industrial projects (<a href="http://www.s-code.info/">S-CODE</a> and <a href="https://journals.sagepub.com/doi/full/10.1177/09544097211059303">High Speed Rail Monitoring</a>) and one research project (<a href="https://royalsociety.org/grants-schemes-awards/grants/international-exchanges/">RS Exchange</a>); 
                Published research outcomes, outlined in more than 10 papers in various IEEE, IET, and IMechE journals.
                And, is the only PhD graduate in Engineering of the Year 2022 to have passed the PhD viva with "no corrections".

              </p>
              <p style="text-align:center">
                <a href="mailto:jxy404@outlook.com">Email</a> &nbsp/&nbsp
                <a href="data/JIAQI YE-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Jiaqi Ye-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Gn39XzgAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jiaqi-ye-1490904/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Jiaqi New.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Jiaqi New_circle.jpg" class="hoverZoomLink"></a>
        </td>
      </tr>
  </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading style="display: block; margin-bottom: 20px;">Education Experience</heading>
                <div style="display: flex; align-items: center; margin-bottom: 20px;">
                    <img src="images/uob_logo.png" alt="UoB Logo" style="width:100px;height:auto;margin-right:10px;">
                    <div>
                        <p>
                            Ph.D.(EESE), <a href="https://www.birmingham.ac.uk/index.aspx"><strong>University of Birmingham (UoB)</strong></a>, 2017-2022, w/<a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>, <a href="http://eic.hust.edu.cn/professor/yangyou/">Cilve Roberts</a>.
                        </p>
                        <p>
                            MRes.(EESE), <a href="https://www.birmingham.ac.uk/index.aspx"><strong>University of Birmingham (UoB)</strong></a>, 2015-2017, w/<a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>, <a href="http://eic.hust.edu.cn/professor/yangyou/">Cilve Roberts</a>.
                        </p>
                    </div>
                </div>
                <div style="display: flex; align-items: center;">
                    <img src="images/hust_logo.png" alt="HUST Logo" style="width:100px;height:auto;margin-right:10px;">
                    <p>
                        B.Eng.(EESE), <a href="https://en.wikipedia.org/wiki/Huazhong_University_of_Science_and_Technology"><strong>Huazhong University of Science and Technology (HUST)</strong></a>, 2011-2015, w/<a href="http://eic.hust.edu.cn/professor/yangyou/">You Yang</a>.
                    </p>
                </div>              
            </td>
        </tr>
    </tbody>
</table>

<!-- ---here--- -->

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Project Experience <span style="font-size: smaller;">(Tap the pic to unleash the demo!)</span></heading>
            <p></p>           
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="robottracking_stop()" onmouseover="robottracking_start()" bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='robottracking_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/RobotTracking.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/RobotTracking.jpg' width="180">
              </div>
              <script type="text/javascript">
                function robottracking_start() {
                  document.getElementById('robottracking_image').style.opacity = "1";
                }

                function robottracking_stop() {
                  document.getElementById('robottracking_image').style.opacity = "0";
                }
                robottracking_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Dynamic Robot Manipulation with Body Landmark Detection, Inertial Measurement, and Depth Sensing</papertitle>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/mechanical/hajiyavand-amir.aspx">Amir Hajiyavand</a>
              <br>
              <em>12-2023 to Present</em>  
              <p>In the field of robot manipulation, obtaining precise target coordinates in 3D space is imperative. 
                This project develops a real-time robot2point tracking system. In this specific example, the system utilizes 
                (1) a pre-trained deep learning model to recognize human landmarks (X, Y), (2) a depth camera to determine the distance to the target point (Z),
                and (3) an IMU to maintain the camera pose in 3D space. Beyond robot manipulation, enhanced with various sensors, 
                the system supports human body analysis, 3D scanning and modeling, and more.
              </p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()" bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/movie_resized.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/UR_automation1.jpg' width="180"></div>
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>UR and Machine Vision Enhanced Manufacturing Line Automation</papertitle>
              <br>
              <strong>Jiaqi Ye</strong>, 
              <a href="https://www.birmingham.ac.uk/staff/profiles/mechanical/hajiyavand-amir.aspx">Amir Hajiyavand </a>
              <br>
              <em>08-2022 to 12-2023</em>  
              <br>	
              <p>This industrial project aims to seamlessly integrate a UR robot platform into a live machinery components manufacturing line, 
                replacing a human operator to carry out repetitive quality inspection processes. The design consists of three modules: 
                <br><strong>(1) Vision Module:</strong> This module utilizes customized computer vision algorithms to track and locate the targeted machine on the manufacturing line; 
                <br><strong>(2) Central PLC Module:</strong> The Programmable Logic Controller(PLC) module reads information from the Vision Module and other PLCs on the 
                manufacturing line, sending commands accordingly to the robot; 
                <br><strong>(3) Robot Platform:</strong> The robot platform receives commands from the PLC and carries out corresponding inspection processes.</p>
            </td>
          </tr>

          <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()" bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/Jiaqi_spring_detection_resized.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/Spring_detection.jpg' width="180">
              </div>
              <script type="text/javascript">
                function blocknerf_start() {
                  document.getElementById('blocknerf_image').style.opacity = "1";
                }

                function blocknerf_stop() {
                  document.getElementById('blocknerf_image').style.opacity = "0";
                }
                blocknerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Deep Learning based Track-side Vision System for EuroTunnel</papertitle>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>
              <br>
              <em>07-2023 to Present</em>  
              <p>This project addresses a critical need by developing an innovative automatic vision system for the Eurotunnel (Folkestone - Calais). 
                At its core, this system is designed to inspect the status of crucial load wagon components before the loading process. 
                The importance of such a system lies in its potential to enhance safety, operational efficiency, and cost-effectiveness along this vital freight train route.
                Our approach leverages a customized YOLO series model, tailored to the unique demands of the Eurotunnel environment. The development of the system holds the promise of significantly improving the normal operation of freight trains along this route.
              </p>
            </td>
          </tr>

            <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/TIM2_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/TIM2_before.png' width="180">
              </div>
              <script type="text/javascript">
                function hnerf_start() {
                  document.getElementById('hnerf_image').style.opacity = "1";
                }

                function hnerf_stop() {
                  document.getElementById('hnerf_image').style.opacity = "0";
                }
                hnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10129146">
                <papertitle>Deep Learning and Laser-Based 3-D Pixel-Level Rail Surface Defect Detection Method</papertitle>
              </a>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>,
              <a href="https://www.linkedin.com/in/qianyu-chen-uob/?originalSubdomain=uk">Qianyu Chen</a>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/roberts-clive.aspx">Clive Roberts</a> <br>
              <em>IEEE Transactions on Instrumentation and Measurement</em>, vol. 72, pp. 1-12, 2023.
              <br>
              <p>Proposed a customized U-Net model, which allows you to process point cloud data in an 
                 end-to-end manner for tasks such as 3D surface defect detection and reconstruction. Main innovations: 
                 <br><strong>(1) Customized deep semantic network based on the U-Net structure</strong> <br><strong>(2) Transfer learning</strong> 
                 <br><strong>(3) Establishment of point cloud datasets</strong></p>
            </td>
          </tr>

          <tr onmouseout="hnerf2_stop()" onmouseover="hnerf2_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hnerf2_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/TIM1_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/TIM1_before.png' width="180">
              </div>
              <script type="text/javascript">
                function hnerf2_start() {
                  document.getElementById('hnerf2_image').style.opacity = "1";
                }

                function hnerf2_stop() {
                  document.getElementById('hnerf2_image').style.opacity = "0";
                }
                hnerf2_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10129146">
                <papertitle>Integration of Multiple Sensors for Noncontact Rail Profile Measurement and Inspection</papertitle>
              </a>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>,
              <a href="https://scholar.google.co.uk/citations?user=sN5BNaYAAAAJ&hl=en">Dingcheng Zhang</a>,
              <a href="https://www.linkedin.com/in/qianyu-chen-uob/?originalSubdomain=uk">Qianyu Chen</a>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/roberts-clive.aspx">Clive Roberts</a><br>
              <em>IEEE Transactions on Instrumentation and Measurement</em>, vol. 70, pp. 1-12, 2021.
              <br>
              <a href="http://www.s-code.info/">project page</a>
              /
              <a href="http://www.s-code.info/media/1100/d3-1-next-generation-control-monitoring-and-sensor-systems.pdf">report</a>
              <p></p>

              <p>Developed a six-degrees-of-freedom portable scanner, integrating a laser triangulation sensor, an HD camera, 
                and an inertial measurement unit (IMU), for high-precision object profile measurement. Main innovations: 
                <br><strong>(1) Multi-sensor fusion and miniaturisation</strong><br><strong>(2) High-precision point cloud data registration</strong></p>
            </td>
          </tr>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/partF1_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/partF1_before.jpg' width="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://m-niemeyer.github.io/regnerf/index.html">
                <papertitle>Use of a 3D model to improve the performance of laser-based railway track inspection</papertitle>
                <font color="red"><strong>(Editor's Choice)</strong></font>
              </a>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/roberts-clive.aspx">Clive Roberts</a><br>
        <em>Part F: Journal of Rail and Rapid Transit, </em>2019 
              <br>
              <a href="https://s3-storage-classes-demos-jiaqi-2023.s3.eu-west-2.amazonaws.com/Surface+scanning+and+reconstruction.mp4">video</a>
              <p></p>
              <p>Developed a novel 3D perceptual system, based on a low-cost 2D laser sensor, 
                for the fast characterization and assessment of object surface conditions such as surface defects and roughness.
                Main innovations:
                <br><strong>(1)Low-cost strategy for conducting 3D measurement using 2D scanners </strong>
                <br><strong>(2)Dedicated pipeline for high-precision 3D reconstruction of large object</strong>   
              </p>
            </td>
          </tr> 
					
          <tr onmouseout="urf_stop()" onmouseover="urf_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='urf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/PartF2_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/PartF2_before.jpg' width="180">
              </div>
              <script type="text/javascript">
                function urf_start() {
                  document.getElementById('urf_image').style.opacity = "1";
                }

                function urf_stop() {
                  document.getElementById('urf_image').style.opacity = "0";
                }
                urf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://journals.sagepub.com/doi/full/10.1177/09544097211059303">
                <papertitle>A vision-based method for line-side switch rail condition monitoring and inspection</papertitle>
              </a>
              <br>
              <strong>Jiaqi Ye</strong>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/stewart-edward.aspx">Edward Stewart</a>,
              <a href="https://www.linkedin.com/in/qianyu-chen-uob/?originalSubdomain=uk">Qianyu Chen</a>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/chen-lei.aspx">Lei Chen</a>,
              <a href="https://www.birmingham.ac.uk/staff/profiles/eese/roberts-clive.aspx">Clive Roberts</a><br>
							<em>Part F: Journal of Rail and Rapid Transit, </em>2022 
              <br>
              <p>
								Designed and deployed a vision-based 24-hr remote condition monitoring system for a reciprocating 
                device (Switch rail) in the high-speed railway. Main contributions: <br><strong>(1) Embedded vision system for the working environment</strong>
                <br><strong>(2)Dedicated algorithms for reliable detection and tracking of the object in varying lighting conditions</strong></p>
            </td>
          </tr> 

        </tbody></table>


        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <heading>Other Projects</heading>

          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
                <!-- Static Image -->
                <img src='images/friendly-chatbot.jpg' class="chatbot-image" alt="Chatbot Image">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- Clickable Text Link -->
                <a href="https://mysillychatbot-2.streamlit.app/" class="chatbot-link" target="_blank">My Chatbot (click to play)</a>
                <br><strong>Jiaqi Ye</strong><br>
                <p>
                  (1)Created my app GUI using streamlit; (2)Uploaded to a github repo for versioning control; (3)Dployed my app to streamlit cloud as the host (could use other platforms like Azure Container Apps).
                  <br>In progress ... to find a proper free LLM API...to containrise the app using Docker for easier deployment.
                </p>
            </td>
        </tr>

          <tr onmouseout="urf3_stop()" onmouseover="urf3_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
                <div class="one">
                    <div id='urf3_video' style="display:none;">
                        <video width="100%" height="100%" muted autoplay loop>
                            <source src="images/processed2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <div id='urf3_img'>
                        <img src='images/RViz_Sim.png' width="180">
                    </div>
                </div>
                <script type="text/javascript">
                    function urf3_start() {
                        document.getElementById('urf3_img').style.display = "none";
                        document.getElementById('urf3_video').style.display = "block";
                    }
        
                    function urf3_stop() {
                        document.getElementById('urf3_img').style.display = "block";
                        document.getElementById('urf3_video').style.display = "none";
                    }
                    urf3_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Deep Mapping-Based Robot Control</papertitle>
              <br>
              <strong>Jiaqi Ye</strong><br>
              In progress ...

              <p>Using a custmoised deep learning model to dynamically generate robotic arm trajectories from object poses, enabling real-time adaptation to changing environments and complex motions (e.g. fast tracking, fast pick and place).
                <br><strong>(1)Deep Learning,</strong> <strong>(2)CNN and LSTM, </strong> <strong> and (2)Robotics </strong></p>
              </td>
          </tr>
        
        
          <tr onmouseout="urf1_stop()" onmouseover="urf1_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
                <div class="one">
                    <div id='urf1_video' style="display:none;">
                        <video width="100%" height="100%" muted autoplay loop>
                            <source src="images/YOLOV8 Publication1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <div id='urf1_img'>
                        <img src='images/PartF3_before.jpg' width="180">
                    </div>
                </div>
                <script type="text/javascript">
                    function urf1_start() {
                        document.getElementById('urf1_img').style.display = "none";
                        document.getElementById('urf1_video').style.display = "block";
                    }
        
                    function urf1_stop() {
                        document.getElementById('urf1_img').style.display = "block";
                        document.getElementById('urf1_video').style.display = "none";
                    }
                    urf1_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>YOLOV8-based electronic components detection and decoding platform</papertitle>
              <br>
              <strong>Jiaqi Ye</strong><br>
              <a href="https://github.com/yjq349825834/YOLO-based-electronic-components-detection-">project page</a>
              /
              <a href="https://docs.ultralytics.com/">reference</a>
              <p></p>

              <p>A fast electronic components detection and deoding (resistance) platform developed to benefit UoB EESE students on their final year projects by facilitating 
                 circuit board developement processes, based on: 
                <br><strong>(1) A pipeline running two custom trained YOLOV8 models</strong><br><strong>(2)PyTorch-GPU with increased processing speeds </strong></p>
              </td>
          </tr>

          <tr style="height: 5px;">
            <td colspan="2"></td>
        </tr>

          <tr onmouseout="urf2_stop()" onmouseover="urf2_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
                <div class="one">
                    <div id='urf2_video' style="display:none;">
                        <video width="100%" height="100%" muted autoplay loop>
                            <source src="images/SLAM.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <div id='urf2_img'>
                        <img src='images/SLAM.jpg' width="180">
                    </div>
                </div>
                <script type="text/javascript">
                    function urf2_start() {
                        document.getElementById('urf2_img').style.display = "none";
                        document.getElementById('urf2_video').style.display = "block";
                    }
        
                    function urf2_stop() {
                        document.getElementById('urf2_img').style.display = "block";
                        document.getElementById('urf2_video').style.display = "none";
                    }
                    urf2_stop();
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Robot Localisation and Mapping</papertitle>
              <br>
              <strong>Jiaqi Ye</strong><br>
              <p></p>

              <p>Mobile robot navigation using: 
                <br><strong>(1) SLAM </strong><strong> and (2)Probabilistic Localisation  </strong></p>
            </td>
          </tr>

          <!-- <tr style="height: 30px;">
            <td colspan="2"></td>
        </tr>

        <tr>
          <td style="padding:0px;width:25%;vertical-align:middle">
              <div class="one">
                  <div id='urf3_img'>
                      <img src='images/SLAM.jpg' width="180">
                  </div>
              </div>
              <script type="text/javascript">
                // No need for separate functions to start and stop since we always want the image
                document.getElementById('urf3_img').style.display = "block";
            </script>    
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Robot Localisation and Mapping</papertitle>
              <br>
              <strong>Jiaqi Ye</strong><br>
              <p></p>
              <p>Mobile robot navigation using: 
                  <br><strong>(1) SLAM </strong><strong> and (2)Probabilistic Localisation  </strong></p>
          </td>
      </tr>   -->

    

        </tbody></table>
        



        <!-- Spacer row -->
        <table width="100%" cellspacing="0" cellpadding="0">
          <tr>
            <td style="height: 20px;"></td> <!-- Adjust the height as needed for spacing -->
          </tr>
        </table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td>
              <p></p>
              <heading>Publications</heading>
              <p></p>
            </td>
          </tr>
        </tbody></table>

      <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <tr>
        <td style="padding:0px;width:0%;vertical-align:middle">
          [1] <strong>J. Ye</strong>, E. Stewart, Q. Chen, C. Roberts, A. M. Hajiyavand and Y. Lei, <a href="https://ieeexplore.ieee.org/abstract/document/10129146">"Deep Learning and Laser-Based 3-D Pixel-Level Rail Surface Defect Detection Method,"</a> 
          in <em>IEEE Transactions on Instrumentation and Measurement</em>, 72:1-12, 2023.
          <p>
          [2] <strong>J. Ye</strong>, E. Stewart, Q. Chen, et al, <a href="https://journals.sagepub.com/doi/full/10.1177/09544097211059303">"A vision-based method for line-side switch rail condition monitoring and inspection,</a> 
          in <em>Part F: Journal of Rail and Rapid Transit</em>, 236(8):986-996, 2022.
          <p> 
          [3] <strong>J. Ye</strong>, E. Stewart, D. Zhang, et al, <a href="https://ieeexplore.ieee.org/abstract/document/9317838">"Integration of Multiple Sensors for Noncontact Rail Profile Measurement and Inspection,"</a> 
          in <em>IEEE Transactions on Instrumentation and Measurement</em>, 70:1-12, 2021.
          <p>
          [4] <strong>J. Ye</strong>, E. Stewart, D. Zhang, et al, <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2019.1616">"Method for automatic railway track surface defect classification and evaluation using a laser-based 3D model,"</a> 
          in <em>IET Image Processing</em>, 14: 2701-2710, 2020.
          <p> 
          [5] <strong>J. Ye</strong>,  E. Stewart, C. Roberts, et al, <a href="https://journals.sagepub.com/doi/full/10.1177/0954409718795714">"Use of a 3D model to improve the performance of laser-based railway track inspection,"</a> 
          in <em>Part F: Journal of Rail and Rapid Transit</em>, 233: 337-355, 2019. 
          <P>
          [6] J. Yang, E.Stewart, <strong>J. Ye</strong>, M.Entezami, C.Roberts, <a href="https://www.mdpi.com/2076-3417/13/2/942"> "An Improved VMD Method for Use with Acoustic Impact Response Signals to Detect Corrosion at the Underside of Railway Tracks,"</a>
          in <em> Applied Science</em>, 13(2):942, 2023.  
          <p>
          [7] D. Zhang, E. Stewart, <strong>J. Ye</strong>, et al, <a href="https://ieeexplore.ieee.org/abstract/document/8765772">"Roller Bearing Degradation Assessment Based on a Deep MLP Convolution Neural Network Considering Outlier Regions,"</a> 
          in <em>IEEE Transactions on Instrumentation and Measurement</em>, 69(6):2996-3004, 2020.  
          <p>
          [8] Q. Chen, G. Nicholson, C. Roberts, <strong>J. Ye</strong>, et al, <a href="https://ieeexplore.ieee.org/abstract/document/9216143">"Improved Fault Diagnosis of Railway Switch System Using Energy-Based Thresholding Wavelets (EBTW) and Neural Networks,"</a> 
            in <em>IEEE Transactions on Instrumentation and Measurement</em>, 70:1-12, 2021. 
          <p>
          [9] Q. Chen, G. Nicholson, <strong>J. Ye</strong>, et al, <a href="https://www.mdpi.com/1424-8220/20/19/5504">"Estimating Residual Life Distributions of Complex Operational Systems Using a Remaining Maintenance Free Operating Period (RMFOP)-Based Methodology,"</a> 
          in <em>Sensors</em>, 20(19): 5504, 2020.    
          <p>
          [10]Q. Chen, G. Nicholson, <strong>J. Ye</strong>, et al, <a href="https://ieeexplore.ieee.org/abstract/document/9115545">"Fault Diagnosis Using Discrete Wavelet Transform (DWT) and Artificial Neural Network (ANN) for A Railway Switch,"</a> 
          in <em>2020 Prognostics and Health Management Conference (PHM-Besan√ßon)</em>, pp. 67-71, 2020. 
        </td>  
      </tr>
      </tbody></table>  

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td>
              <p>
              <heading>Misc</heading>
              <p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:0px;width:0%;vertical-align:middle">
            <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center"> -->
              <strong>Invited Reviewer of Journals:</strong><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9424">„ÄäIEEE Transactions on Industrial Informatics„Äã</a>¬∑
              <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19">„ÄäIEEE Transactions on Instrumentation and Measurement„Äã</a>¬∑
              <a href="https://ietresearch.onlinelibrary.wiley.com/page/journal/17519667/journal-metrics">„ÄäIET Image Processing</a>„Äã¬∑ 
              <a href="https://www.mdpi.com/journal/sensors">„ÄäMDPI Sensors„Äã</a>
              <br>
              <p>
              <strong>Teaching Assistant of Courses:</strong> UoB-HUST Summer Laboratory ¬∑ Python Progrramming ¬∑ Digital Systems and Embedded Computing </a>
              <br>
              <p>
              <strong>STEM Ambassador</strong>, <a href="https://www.stem.org.uk/">STEM Learning 2022</a>
              <br>
              <p>
                <strong>Awards:</strong> No Corrections Passing PhD Viva (UoB, 04/2022) ¬∑ 
                <a href="https://journals.sagepub.com/collection-index/pif"> SAGE Best Journal Paper Award(IMechE, 03/3019)</a> ¬∑ 
                Best Master Research Thesis (BCRRE, 09/2017)
            </td>
          </tr>
         </tbody></table>

      <hr class="solid">
    
      <!-- <Map of the website traffic> -->
      <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=n&d=OevCJoYZ645qOkbZTTxwuJsx4BwQ033PVGlV6ppxWbA&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script> -->
      <!-- script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=n&d=OevCJoYZ645qOkbZTTxwuJsx4BwQ033PVGlV6ppxWbA&co=ffffff&cmo=ff5353&cmn=ff5353&ct=808080'></script> -->
      <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=R641KyYfVKN0mLdZlS2MVjXGhByvz4aMVFiit5GW4E0&cl=ffffff&w=a"></script>

    
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Design and source code from  <a href="https://github.com/jonbarron/website" target="_blank" rel="noopener noreferrer">this websie</a>.
                  </p>
                </td>
              </tr>
            </tbody></table>
      
          </td>
        </tr>
      </table>
    </body>
</html>
